{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center; font-size: 20px;\"><b>Stats216v: Statistical Learning</b></div>\n",
    "\n",
    "<br>\n",
    "<div style=\"text-align: center\">Stanford University</div>\n",
    "<div style=\"text-align: center\">Summer 2017</div>\n",
    "<div style=\"text-align: center\">Gyu-Ho Lee (<a href=\"mailto:gyuhox@gmail.com\">gyuhox@gmail.com</a>)</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8. Tree-Based Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 8.1.R1\n",
    "\n",
    "Using the decision tree on page 5 of the notes, what would you predict for the log salary of a player who has played for 4 years and has 150 hits?\n",
    "\n",
    "<img src=\"./chapter-08-tree-based-methods-1.png\" alt=\"chapter-08-tree-based-methods-1.png\" style=\"width: 250px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:blue\">\n",
    "Gyu-Ho's Answer: 5.11.\n",
    "</span>\n",
    "\n",
    "The player has played less than 4.5 years, so at the first split we follow the left branch. There are no further splits, so we predict 5.11."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "##### 5.2.R1\n",
    "\n",
    "<img src=\"./chapter-08-tree-based-methods-2.png\" alt=\"chapter-08-tree-based-methods-2.png\" style=\"width: 400px;\"/>\n",
    "\n",
    "Imagine that you are doing cost complexity pruning as defined on page 18 of the notes. You fit two trees to the same data: $T_{1}$ is fit at $α = 1$ and $T_{2}$ is fit at $α = 2$. Which of the following is true?\n",
    "\n",
    "1. $T_{1}$ will have at least as many nodes as $T_{2}$.\n",
    "2. $T_{1}$ will have at most as many nodes as $T_{2}$.\n",
    "3. Not enough information is given in the problem to decide."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:blue\">\n",
    "Gyu-Ho's Answer: Not enough information is given in the problem to decide.\n",
    "</span>\n",
    "\n",
    "<span style=\"color:red\">\n",
    "A higher value of $alpha$ corresponds to a higher penalty on the complexity of the tree. This means that $T_{1}$ will have at least as many nodes as $T_{2}$.\n",
    "</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "##### 8.3.R1\n",
    "\n",
    "You have a bag of marbles with 64 red marbles and 36 blue marbles.\n",
    "\n",
    "What is the value of the Gini Index for that bag? Give your answer to the nearest hundredth:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:blue\">\n",
    "Gyu-Ho's Answer: $G = \\sum_{k=1}^{K} \\hat{p}_{mk}(1-\\hat{p}_{mk}) = (64/100)(36/100) + (36/100)(64/100) = 0.4608$\n",
    "</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "##### 8.3.R2\n",
    "\n",
    "You have a bag of marbles with 64 red marbles and 36 blue marbles.\n",
    "\n",
    "What is the value of the Cross-Entropy? Give your answer to the nearest hundredth (using log base e, as in R)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<span style=\"color:blue\">\n",
    "Gyu-Ho's Answer: $D = -\\sum_{k=1}^{K} \\hat{p}_{mk} \\log \\hat{p}_{mk} = -(.64 \\times \\log .64 + .36 \\times \\log .36) = 0.6534$\n",
    "</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 8.4.R1\n",
    "\n",
    "Suppose we produce ten bootstrap samples from a data set containing red and green classes. We then apply a classification tree to each bootstrap sample and, for a specific value of X, produce 10 estimates of P(Class is Red|X):\n",
    "\n",
    "0.1,0.15,0.2,0.2,0.55,0.6,0.6,0.65,0.7, and 0.75\n",
    "\n",
    "There are two common ways to combine these results together into a single class prediction. One is the majority vote approach discussed in the notes. The second approach is to classify based on the average probability.\n",
    "\n",
    "What is the final classification under the majority vote method?:\n",
    "\n",
    "1. red\n",
    "2. green"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:blue\">\n",
    "Gyu-Ho's Answer: 1.\n",
    "</span>\n",
    "\n",
    "6 of the 10 probabilities are greater than 1/2, so the majority vote method will select red."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 8.4.R2\n",
    "\n",
    "What is the final classification under the average probability method?:\n",
    "\n",
    "1. red\n",
    "2. green"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:blue\">\n",
    "Gyu-Ho's Answer: 2.\n",
    "</span>\n",
    "\n",
    "The average of the probabilities is 0.45, so the average probability method will select green."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 8.5.R1\n",
    "\n",
    "In order to perform Boosting, we need to select 3 parameters: number of samples B, tree depth d, and step size λ.\n",
    "\n",
    "How many parameters do we need to select in order to perform Random Forests?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:blue\">\n",
    "Gyu-Ho's Answer: 2.\n",
    "</span>\n",
    "\n",
    "To perform Random Forests we need to select 2 parameters: number of samples B and m= number of variables sampled at each split."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 8.R.R1\n",
    "\n",
    "You are trying to reproduce the results of the R labs, so you run the following command in R:\n",
    "\n",
    "> library(tree)\n",
    "\n",
    "As a response, you see the following error message:\n",
    "\n",
    "Error in library(tree) : there is no package called ‘tree’\n",
    "\n",
    "What went wrong?\n",
    "\n",
    "1. You meant to use 'require(tree)'.\n",
    "2. You meant to use 'library(\"tree\")'.\n",
    "3. The tree package is not installed on your computer.\n",
    "4. Nothing is wrong, that error message could not be produced by R. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:blue\">\n",
    "Gyu-Ho's Answer: 3.\n",
    "</span>\n",
    "\n",
    "In order to install the package, run `install.packages()` or use the package installer through the R menu bar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error in library(tree): there is no package called 'tree'\n",
     "output_type": "error",
     "traceback": [
      "Error in library(tree): there is no package called 'tree'\nTraceback:\n",
      "1. library(tree)",
      "2. stop(txt, domain = NA)"
     ]
    }
   ],
   "source": [
    "library(tree)\n",
    "print(\"Libraries have been loaded!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Updating HTML index of packages in '.Library'\n",
      "Making 'packages.html' ... done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"Libraries have been loaded!\"\n"
     ]
    }
   ],
   "source": [
    "install.packages(\"tree\")\n",
    "library(tree)\n",
    "library(\"tree\")\n",
    "print(\"Libraries have been loaded!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 8.Q1\n",
    "\n",
    "The tree building algorithm given on pg 13 is described as a Greedy Algorithm. Which of the following is also an example of a Greedy Algorithm?\n",
    "\n",
    "1. The Lasso\n",
    "2. Support Vector Machines\n",
    "3. The Bootstrap\n",
    "4. Forward Stepwise Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:blue\">\n",
    "Gyu-Ho's Answer: Regression tree is *greedy* because at each step of the tree-building process, the best split is made at that particular step, rather than looking ahead and picking a split that will lead to a better tree in some future step. Forward stepwise selection is a greedy algorithm.\n",
    "</span>\n",
    "\n",
    "Forward Stepwise Selection is a Greedy Algorithm because at each step it selects the variable that improves the current model the most. There is no guarantee that the final result will be optimal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 8.Q2\n",
    "\n",
    "Examine the plot on pg 23. Assume that we wanted to select a model using the one-standard-error rule on the Cross-Validated error. What tree size would end up being selected?\n",
    "\n",
    "<img src=\"./chapter-08-tree-based-methods-3.png\" alt=\"chapter-08-tree-based-methods-3.png\" style=\"width: 400px;\"/>\n",
    "\n",
    "1. 1\n",
    "2. 2\n",
    "3. 3\n",
    "4. 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:blue\">\n",
    "Gyu-Ho's Answer: 3.\n",
    "</span>\n",
    "\n",
    "<span style=\"color:red\">\n",
    "2.\n",
    "</span>\n",
    "\n",
    "Cross-Validated error is minimized at tree size 3. The error for Tree size 2 is within one standard error of the minimum, but the error for tree size 1 is not. Thus, the one-standard-error rule selects tree size 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 8.Q3\n",
    "\n",
    "Suppose I have two qualitative predictor variables, each with three levels, and a quantitative response. I am considering fitting either a tree or an additive model. For the additive model, I will use a piecewise-constant function for each variable, with a separate constant for each level. Which model is capable of fitting a richer class of functions:\n",
    "\n",
    "1. Tree\n",
    "2. Additive Model\n",
    "3. They are equivalent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:blue\">\n",
    "Gyu-Ho's Answer: 1.\n",
    "</span>\n",
    "\n",
    "Although each split of the tree makes two partitions, it can fit interactions, while the additive model cannot. With enough splits the tree can fit a full 3x3 regression surface."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.3.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
