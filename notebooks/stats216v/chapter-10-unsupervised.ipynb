{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center; font-size: 20px;\"><b>Stats216v: Statistical Learning</b></div>\n",
    "\n",
    "<br>\n",
    "<div style=\"text-align: center\">Stanford University</div>\n",
    "<div style=\"text-align: center\">Summer 2017</div>\n",
    "<div style=\"text-align: center\">Gyu-Ho Lee (<a href=\"mailto:gyuhox@gmail.com\">gyuhox@gmail.com</a>)</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 10. Unsupervised Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.1.R\n",
    "\n",
    "Which of the following is the best example of a Qualitative Variable?\n",
    "\n",
    "1. Height\n",
    "2. Age\n",
    "3. Speed\n",
    "4. Color"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:blue\">\n",
    "Gyu-Ho's Answer: 4.\n",
    "</span>\n",
    "\n",
    "Colors are discrete values with no clear ordering. Height, Age, and Speed are all continuous."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.1.R2\n",
    "\n",
    "Judging from the plots on page 2 of the notes, which should be the better predictor of Default: Income or Balance?\n",
    "\n",
    "<img src=\"./chapter-04-classification-1.png\" alt=\"chapter-04-classification-1.png\" style=\"width: 450px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:blue\">\n",
    "Gyu-Ho's Answer: Balance.\n",
    "</span>\n",
    "\n",
    "Default is clearly associated with higher balances. On the other hand, the rate of default seems fairly constant across income levels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "##### 4.2.R1\n",
    "\n",
    "Using the model on page 8 of the notes, what value of Balance will give a predicted Default rate of 50%? (within 3 units of accuracy)\n",
    "\n",
    "<img src=\"./chapter-04-classification-2.png\" alt=\"chapter-04-classification-2.png\" style=\"width: 450px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:blue\">\n",
    "Gyu-Ho's Answer: 1937.\n",
    "\n",
    "$math.pow(math.e, -10.6513+0.0055*1937) / (1 + math.pow(math.e, -10.6513+0.0055*1937)) * 100.$\n",
    "</span>\n",
    "\n",
    "We know that $logit(.5) = β_{0} + β_{1} * Balance$. Thus, $Balance = (logit(.5) - β_{0}) / β_{1} = (log(.5/(1-.5)) + 10.6513)/.0055 = 1936.6$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "##### 4.3.R1\n",
    "\n",
    "Suppose we collect data for a group of students in a statistics class with variables $X_{1}$ = hours studied, $X_{2}$ = undergrad GPA, and $Y$ = receive an A. We fit a logistic regression and produce estimated coefficients $\\hat{β}_{0} = −6$, $\\hat{β}_{1} = 0.05$, $\\hat{β}_{2} = 1$.\n",
    "\n",
    "Estimate the probability that a student who studies for 40h and has an undergrad GPA of 3.5 gets an A in the class (within 0.01 accuracy):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:blue\">Gyu-Ho's Answer: 0.37.</span>\n",
    "\n",
    "$\\hat{p}(X) = \\frac{e^{\\hat{β}_{0} + \\hat{β}_{1} X_{1} + \\hat{β}_{2} X_{2}}}{1 + e^{\\hat{β}_{0} + \\hat{β}_{1} X_{1} + \\hat{β}_{2} X_{2}}} = \\frac{e^{-6 + 0.05 X_{1} + X_{2}}}{1 + e^{-6 + 0.05 X_{1} + X_{2}}} = \\frac{e^{-6 + 0.05 * 40 + 3.5}}{1 + e^{-6 + 0.05 * 40 + 3.5}} = 0.37754$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "##### 4.3.R2\n",
    "\n",
    "How many hours would that student need to study to have a 50% chance of getting an A in the class?:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<span style=\"color:blue\">\n",
    "Gyu-Ho's Answer: 50.\n",
    "</span>\n",
    "\n",
    "$P((h, 3.5)) = \\frac{e^{-6 + 0.05 * h + 3.5}}{1 + e^{-6 + 0.05 * h + 3.5}} = 0.5$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.4.R\n",
    "\n",
    "In which of the following problems is Case/Control Sampling LEAST likely to make a positive impact?\n",
    "\n",
    "1. Predicting a shopper's gender based on the products they buy\n",
    "2. Finding predictors for a certain type of cancer\n",
    "3. Predicting if an email is Spam or Not Spam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:blue\">\n",
    "Gyu-Ho's Answer: 1.\n",
    "</span>\n",
    "\n",
    "Case/Control sampling is most effective when the prior probabilities of the classes are very unequal. We expect this to be the case for the cancer and spam problems, but not the gender problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.5.R1\n",
    "\n",
    "Suppose that in Ad Clicks (a problem where you try to model if a user will click on a particular ad) it is well known that the majority of the time an ad is shown it will not be clicked. What is another way of saying that?\n",
    "\n",
    "1. Ad Clicks have a low Prior Probability.\n",
    "2. Ad Clicks have a high Prior Probability.\n",
    "3. Ad Clicks have a low Density.\n",
    "4. Ad Clicks have a high Density."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:blue\">\n",
    "Gyu-Ho's Answer: 1.\n",
    "</span>\n",
    "\n",
    "Whether or not an ad gets clicked is a Qualitative Variable. Thus, it does not have a density. The Prior Probability of Ad Clicks is low because most ads are not clicked."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 4.6.R1\n",
    "\n",
    "Which of the following is NOT a linear function in x:\n",
    "\n",
    "1. $f(x) = a + b^{2} x$\n",
    "2. The discriminant function from LDA\n",
    "3. $δ_{k}(x) = x \\frac{μ_{k}}{σ^{2}} - \\frac{μ^{2}_{k}}{2σ^{2}} + log(π_{k})$\n",
    "4. logit$(P(y=1|x))$ where $P(y=1|x)$ is as in logistic regression\n",
    "5. $P(y=1|x)$ from logistic regression\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:blue\">\n",
    "Gyu-Ho's Answer: 5.\n",
    "</span>\n",
    "\n",
    "$P(y=1|x)$ from logistic regression is not linear because it involves both an exponential function of x and a ratio. Notice that $f(x) = a + b^{2} x$ is not a linear function of b, but is a linear function of x."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.7.R1\n",
    "\n",
    "Why does Total Error keep going down on the graph on page 34 of the notes, even though the False Negative Rate increases?\n",
    "\n",
    "<img src=\"./chapter-04-classification-3.png\" alt=\"chapter-04-classification-3.png\" style=\"width: 450px;\"/>\n",
    "\n",
    "1. The False Negative Rate does not affect Total Error.\n",
    "2. A higher False Negative Rate generally decreases Total Error.\n",
    "3. Positive responses are so uncommon that the False Negatives make up only a small portion of the Total Error.\n",
    "4. All of the above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:blue\">\n",
    "Gyu-Ho's Answer: 3.\n",
    "</span>\n",
    "\n",
    "The Total Error is a weighted average of the False Positive Rate and False Negative Rate. The weights are determined by the Prior Probabilities of Positive and Negative Responses."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.8.R1\n",
    "\n",
    "Which of the following statements best explains the relationship between Quadratic Discriminant Analysis and naive Bayes with Gaussian distributions in each class?\n",
    "\n",
    "1. Quadratic Discriminant Analysis is a more flexible class of models than naive Bayes\n",
    "2. Quadratic Discriminant Analysis is a less flexible class of models than naive Bayes\n",
    "3. Quadratic Discriminant Analysis is an equivalently flexible class of models to naive Bayes\n",
    "4. For some problems Quadratic Discriminant Analysis is more flexible than naive Bayes, for others the opposite is true."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:blue\">\n",
    "Gyu-Ho's Answer: 1.\n",
    "</span>\n",
    "\n",
    "With Gaussian distributions, naive Bayes is equivalent to Quadratic Discriminant Analysis with the additional requirement that each class covariance matrix $Σ_{k}$ be diagonal. Thus, Quadratic Discriminant Analysis is more flexible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.R.R\n",
    "\n",
    "In ch4.R, line 13 is \"attach(Smarket).\" If that line was omitted from the script, which of the following lines would cause an error?:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Updating HTML index of packages in '.Library'\n",
      "Making 'packages.html' ... done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"Libraries have been loaded!\"\n"
     ]
    }
   ],
   "source": [
    "LoadLibraries = function() {\n",
    "    library(MASS)\n",
    "    install.packages(\"ISLR\")\n",
    "    library(ISLR)\n",
    "    print(\"Libraries have been loaded!\")\n",
    "}\n",
    "\n",
    "LoadLibraries()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>'Year'</li>\n",
       "\t<li>'Lag1'</li>\n",
       "\t<li>'Lag2'</li>\n",
       "\t<li>'Lag3'</li>\n",
       "\t<li>'Lag4'</li>\n",
       "\t<li>'Lag5'</li>\n",
       "\t<li>'Volume'</li>\n",
       "\t<li>'Today'</li>\n",
       "\t<li>'Direction'</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 'Year'\n",
       "\\item 'Lag1'\n",
       "\\item 'Lag2'\n",
       "\\item 'Lag3'\n",
       "\\item 'Lag4'\n",
       "\\item 'Lag5'\n",
       "\\item 'Volume'\n",
       "\\item 'Today'\n",
       "\\item 'Direction'\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 'Year'\n",
       "2. 'Lag1'\n",
       "3. 'Lag2'\n",
       "4. 'Lag3'\n",
       "5. 'Lag4'\n",
       "6. 'Lag5'\n",
       "7. 'Volume'\n",
       "8. 'Today'\n",
       "9. 'Direction'\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] \"Year\"      \"Lag1\"      \"Lag2\"      \"Lag3\"      \"Lag4\"      \"Lag5\"     \n",
       "[7] \"Volume\"    \"Today\"     \"Direction\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "names(Smarket)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error in mean(glm.pred == Direction): object 'glm.pred' not found\n",
     "output_type": "error",
     "traceback": [
      "Error in mean(glm.pred == Direction): object 'glm.pred' not found\nTraceback:\n",
      "1. mean(glm.pred == Direction)"
     ]
    }
   ],
   "source": [
    "mean(glm.pred==Direction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error in eval(expr, envir, enclos): object 'train' not found\n",
     "output_type": "error",
     "traceback": [
      "Error in eval(expr, envir, enclos): object 'train' not found\nTraceback:\n",
      "1. glm(Direction ~ Lag1 + Lag2 + Lag3 + Lag4 + Lag5 + Volume, data = Smarket, \n .     family = binomial, subset = train)",
      "2. eval(mf, parent.frame())",
      "3. eval(expr, envir, enclos)",
      "4. stats::model.frame(formula = Direction ~ Lag1 + Lag2 + Lag3 + \n .     Lag4 + Lag5 + Volume, data = Smarket, subset = train, drop.unused.levels = TRUE)",
      "5. model.frame.default(formula = Direction ~ Lag1 + Lag2 + Lag3 + \n .     Lag4 + Lag5 + Volume, data = Smarket, subset = train, drop.unused.levels = TRUE)",
      "6. eval(substitute(subset), data, env)",
      "7. eval(expr, envir, enclos)"
     ]
    }
   ],
   "source": [
    "glm.fit = glm(Direction~Lag1+Lag2+Lag3+Lag4+Lag5+Volume,data=Smarket,family=binomial, subset=train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.Q.1\n",
    "\n",
    "Which of the following tools would be well suited for predicting if a student will get an A in a class based on the student's height, and parents’ income? Select all that apply:\n",
    "\n",
    "1. Linear Discriminant Analysis\n",
    "2. Linear Regression\n",
    "3. Logistic Regression\n",
    "4. Random Guess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:blue\">\n",
    "Gyu-Ho's Answer: 1, 3.\n",
    "</span>\n",
    "\n",
    "<span style=\"color:red\">\n",
    "1, 2, 3.\n",
    "</span>\n",
    "\n",
    "Whether or not a student gets an A is a categorical variables. Thus, we should use a classification technique like LDA or Logistic Regression. For binary classification, linear regression and LDA are almost equivalent."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.3.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
